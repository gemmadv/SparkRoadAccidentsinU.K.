{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d01e43162b64c90ce0048e8a23f3b1b",
     "grade": false,
     "grade_id": "cell-f8987996be9f1238",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Accidentes de tráfico en Reino Unido entre 2010 y 2014 \n",
    "\n",
    "### Disponible en Kaggle en:\n",
    "https://www.kaggle.com/stefanoleone992/adm-project-road-accidents-in-uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a6b4dc108ddf890c659e33701965428",
     "grade": false,
     "grade_id": "cell-f74d7bfd01811789",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Variables y significado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a5a5882319ae0a14393c8d534816a56",
     "grade": false,
     "grade_id": "cell-9cfb34982bd4eb04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Accident_Index: Accident index\n",
    "* Latitude: Accident latitude\n",
    "* Longitude: Accident longitude\n",
    "* Region: Accident region\n",
    "* Urban_or_Rural_Area: Accident area (rural or urban)\n",
    "* X1st_Road_Class: Accident road class\n",
    "* Driver_IMD_Decile: Road IMD Decile\n",
    "* Speed_limit: Road speed limit\n",
    "* Road_Type: Road type\n",
    "* Road_Surface_Conditions: Road surface condition\n",
    "* Weather: Weather\n",
    "* High_Wind: High wind\n",
    "* Lights: Road lights\n",
    "* Datetime: Accident datetime\n",
    "* Year: Accident year\n",
    "* Season: Accident season\n",
    "* Month_of_Year: Accident month\n",
    "* Day_of_Month: Accident day of month\n",
    "* Day_of_Week: Accident day of week\n",
    "* Hour_of_Day: Accident hour of day\n",
    "* Number_of_Vehicles: Accident number of vehicles\n",
    "* Age_of_Driver: Driver age\n",
    "* Age_of_Vehicle: Vehicle age\n",
    "* Junction_Detail: Accident junction detail\n",
    "* Junction_Location: Accident junction location\n",
    "* X1st_Point_of_Impact: Vehicle first point of impact\n",
    "* Driver_Journey_Purpose: Driver journey purpose\n",
    "* Engine_CC: Vehicle engine power (in CC)\n",
    "* Propulsion_Code: Vehicle propulsion code\n",
    "* Vehicle_Make: Vehicle brand\n",
    "* Vehicle_Category: Vehicle brand category\n",
    "* Vehicle_Manoeuvre: Vehicle manoeuvre when accident happened\n",
    "* Accident_Severity: Accident severity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nombre completo del alumno:**  Gemma del Val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28429bd5e3051f643a72b2e5787231f5",
     "grade": false,
     "grade_id": "cell-b4f9c37a2b92d2e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**INSTRUCCIONES**: en cada celda debes responder a la pregunta formulada, asegurándote de que el resultado queda guardado en la(s) variable(s) que por defecto vienen inicializadas a `None`. No se necesita usar variables intermedias, pero puedes hacerlo siempre que el resultado final del cálculo quede guardado exactamente en la variable que venía inicializada a None (debes reemplazar None por la secuencia de transformaciones necesarias, pero nunca cambiar el nombre de esa variable). **No olvides borrar la línea *raise NotImplementedError()* de cada celda cuando hayas completado la solución de esa celda y quieras probarla**.\n",
    "\n",
    "Después de cada celda evaluable verás una celda con código. Ejecútala (no modifiques su código) y te dirá si tu solución es correcta o no. Además de esas pruebas, se realizarán algunas más (ocultas) a la hora de puntuar el ejercicio, pero evaluar dicha celda es un indicador bastante fiable acerca de si realmente has implementado la solución correcta o no. Asegúrate de que, al menos, todas las celdas indican que el código es correcto antes de enviar el notebook terminado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7764e6064699f591cd2896d2430528e",
     "grade": false,
     "grade_id": "cell-69ec0993eeaff3ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Sobre el dataset anterior (accidents_uk.csv) se pide:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Leerlo tratando de que Spark infiera el tipo de dato de cada columna, y cachearlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cef53e4db93cb2b3c2d9517fe2a060c",
     "grade": false,
     "grade_id": "read_csv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "accidentesDF = spark.read\\\n",
    "                 .option (\"header\", \"true\")\\\n",
    "                 .option (\"inferSchema\", \"true\")\\\n",
    "                 .csv (\"gs://ucmbucket1/data/accidents_uk.csv\")\n",
    "accidentesDF.cache () \n",
    "rows = accidentesDF.count ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe7160ffc743634220394f78cbf50bc1",
     "grade": true,
     "grade_id": "read_csv_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "assert(accidentesDF.schema[1].dataType == DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca43d393c55642389e8df6c144d2ada7",
     "grade": false,
     "grade_id": "cell-b90f5b934eda250e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Discretizar la variable **Age_of_Vehicle** utilizando un bucketizer (sin crear un pipeline) en los puntos de corte (0, 2, 5, 10, 15, 20, 35). La discretización debe quedar en una nueva columna de tipo Double llamada **Edad_Vehiculo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "181368fb47ef6bcd7ddc092c78a917db",
     "grade": false,
     "grade_id": "bucketize",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "splits = [-float (\"inf\"), 0, 2, 5, 10, 15, 20, 35, float (\"inf\")]\n",
    "bucketizer = Bucketizer(splits= splits, inputCol= \"Age_of_Vehicle\", outputCol= \"Edad_Vehiculo\")\n",
    "accidentesBucketizedDF = bucketizer.transform (accidentesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c1ac69726ac8effcf1a2124b1e2cd3a",
     "grade": true,
     "grade_id": "bucketize_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(\"Edad_Vehiculo\" in accidentesBucketizedDF.columns)\n",
    "assert(accidentesBucketizedDF.schema.fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d70a7e664d19dc4591f84611f09e19ee",
     "grade": false,
     "grade_id": "cell-fc88821f19453a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Crear un nuevo DF donde la columna \"Age_of_Driver\" ha sido reemplazada por otra de tipo string en la que los valores 1 y 2 son \"Adolescente\", los valores 3 y 4 por \"Joven\", los valores 5 y 6 por \"Adulto\", y los demás valores se dejan sin modificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "accidentesAgeDF = accidentesDF.withColumn (\"Age_of_Driver\", accidentesDF [\"Age_of_Driver\"].cast (StringType ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15cfd95e651ea158ceef6546f46b2fc9",
     "grade": false,
     "grade_id": "renombrar_edad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "accidentesAgeDF = accidentesAgeDF.withColumn (\"Age_of_Driver\",\\\n",
    "                    F.when ((F.col (\"Age_of_Driver\")== 1) |\n",
    "(F.col (\"Age_of_Driver\")== 2), \"Adolescente\")\\\n",
    "                     .when ((F.col (\"Age_of_Driver\")== 3) |\n",
    "(F.col (\"Age_of_Driver\")== 4), \"Joven\")\\\n",
    "                     .when ((F.col (\"Age_of_Driver\")== 5) |\n",
    "(F.col (\"Age_of_Driver\")== 6), \"Adulto\")\\\n",
    "                     .otherwise (F.col (\"Age_of_Driver\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f33a56b8af18220e6b77664c0f11851",
     "grade": true,
     "grade_id": "renombrar_edad_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Age_of_Driver=u'8', count=9195), Row(Age_of_Driver=u'7', count=13338), Row(Age_of_Driver=u'Adolescente', count=57174), Row(Age_of_Driver=u'Adulto', count=67138), Row(Age_of_Driver=u'Joven', count=104987)]\n"
     ]
    }
   ],
   "source": [
    "assert(dict(accidentesAgeDF.dtypes)[\"Age_of_Driver\"] == \"string\")\n",
    "collectedDF = accidentesAgeDF.groupBy(\"Age_of_Driver\").count().orderBy(\"count\").collect()\n",
    "print(collectedDF)\n",
    "assert((collectedDF[0][\"count\"] == 9195) & (collectedDF[0][\"Age_of_Driver\"] == \"8\"))\n",
    "assert((collectedDF[1][\"count\"] == 13338) & (collectedDF[1][\"Age_of_Driver\"] == \"7\"))\n",
    "assert((collectedDF[2][\"count\"] == 57174) & (collectedDF[2][\"Age_of_Driver\"] == \"Adolescente\"))\n",
    "assert((collectedDF[3][\"count\"] == 67138) & (collectedDF[3][\"Age_of_Driver\"] == \"Adulto\"))\n",
    "assert((collectedDF[4][\"count\"] == 104987) & (collectedDF[4][\"Age_of_Driver\"] == \"Joven\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bf6a51a083d12da7458a15389f55049",
     "grade": false,
     "grade_id": "cell-a71a6b17b1e0d613",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Partiendo de `accidentesDF`, crear un nuevo DataFrame de una sola fila que contenga, **por este orden de columnas**, el **número** de categorías existentes para el propósito del viaje, para el tipo de maniobra del vehículo, para las condiciones de la calzada y para la severidad del accidente. Pista: crear las columnas al vuelo con `select`(). Renombrar cada columna de conteo para que se llame igual que la propia columna que estamos contando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2665ce01f871fab23669e7d6bda6bf1c",
     "grade": false,
     "grade_id": "numero_categorias",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "numeroCategoriasDF = accidentesDF.select (F.countDistinct (F.col (\"Driver_Journey_Purpose\").alias (\"Driver_Journey_Purpose\")), \n",
    "                                         F.countDistinct (F.col (\"Vehicle_Manoeuvre\").alias (\"Vehicle_Manoeuvre\")), \n",
    "                                         F.countDistinct (F.col (\"Road_Surface_Conditions\").alias (\"Road_Surface_Conditions\")), \n",
    "                                         F.countDistinct (F.col (\"Accident_Severity\").alias (\"Accident_Severity\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30ebc9730a12379f2bcce1ad04f24e33",
     "grade": true,
     "grade_id": "numero_categorias_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(numeroCategoriasDF.columns) == 4)\n",
    "assert(numeroCategoriasDF.count() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "daf3ab733439611fd66d4910a87d8c46",
     "grade": false,
     "grade_id": "cell-c5ec05706eccd480",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Partiendo de `accidentesAgeDF` definido anteriormente, crear un nuevo DataFrame con tantas filas como posibles propósitos de un viaje, y tantas columnas como rangos de edad habíamos distinguido en dicho DataFrame más una (la del propósito del viaje). Las columnas deben llamarse igual que cada uno de los niveles posibles de rangos de edad. Cada casilla del nuevo DataFrame deberá contener el **porcentaje** del número de accidentes ocurridos en ese tipo de viaje (fila) para ese rango de edad (columna), medido sobre el *total de accidentes ocurridos para ese tipo de viaje*.\n",
    "\n",
    "Pista: se puede hacer todo en una sola secuencia de transformaciones sin variable auxiliar. Calcular primero el conteo, después añadir una columna con los totales de cada tipo de viaje como la suma de las 5 columnas de conteos, y finalmente reemplazar cada columna de conteo por su porcentaje. No debe utilizarse `when` en ningún momento, solo aritmética de columnas. Recuerda cómo desplegar grupos en varias columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29685452c34b0e7e6e9316e3e74a7718",
     "grade": false,
     "grade_id": "viajes_por_edad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "viajesPorEdadDF = accidentesAgeDF.groupBy (\"Driver_Journey_Purpose\").pivot (\"Age_of_Driver\").agg (F.count (\"Age_of_Driver\"))\\\n",
    "    .withColumn (\"Total\", F.col (\"7\")+F.col (\"8\")+F.col (\"Adolescente\")+F.col (\"Adulto\")+F.col (\"Joven\"))\\\n",
    "    .withColumn (\"7\", F.col (\"7\")/F.col (\"Total\"))\\\n",
    "    .withColumn (\"8\", F.col (\"8\")/F.col (\"Total\"))\\\n",
    "    .withColumn (\"Adolescente\", F.col (\"Adolescente\")/F.col (\"Total\"))\\\n",
    "    .withColumn (\"Joven\", F.col (\"Joven\")/F.col (\"Total\"))\\\n",
    "    .withColumn (\"Adulto\", F.col (\"Adulto\")/F.col (\"Total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e85aec10339652ee69e69997a220ba1",
     "grade": true,
     "grade_id": "viajes_por_edad_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(viajesPorEdadDF.columns) >= 6)\n",
    "assert(\"7\" in viajesPorEdadDF.columns)\n",
    "assert(\"8\" in viajesPorEdadDF.columns)\n",
    "assert(\"Adolescente\" in viajesPorEdadDF.columns)\n",
    "assert(\"Joven\" in viajesPorEdadDF.columns)\n",
    "assert(\"Adulto\" in viajesPorEdadDF.columns)\n",
    "assert(viajesPorEdadDF.columns[0] == \"Driver_Journey_Purpose\")\n",
    "assert(viajesPorEdadDF.count() == 5)\n",
    "commuting = viajesPorEdadDF.orderBy(\"Driver_Journey_Purpose\").collect()[0]\n",
    "assert(commuting.Driver_Journey_Purpose.startswith(\"Commuting\"))\n",
    "assert(abs(commuting['7'] - 0.012527948326649396) < 0.001)\n",
    "assert(abs(commuting['8'] - 0.002519785640770) < 0.001)\n",
    "assert(abs(commuting.Adolescente - 0.236327501153423) < 0.001)\n",
    "assert(abs(commuting.Adulto - 0.2791993469851297) < 0.001)\n",
    "assert(abs(commuting.Joven - 0.46942541789402703) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2832ad3d3604af41eccabcc2bb5a5c16",
     "grade": false,
     "grade_id": "cell-9ebe35c4b4325269",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Unir la información obtenida en el paso anterior al DataFrame `accidentesAgeDF`, de manera que **al resultado final se añada una columna nueva llamada `Porcentaje`** que contenga el porcentaje de accidentes que ha habido para ese rango de edad y ese tipo de viaje de entre todos los viajes que ha habido de ese tipo (es decir, el porcentaje adecuado de la tabla anterior). Por ejemplo, si el accidente se produjo en un trayecto de tipo `Commuting...` y la persona es `Joven`, entonces la columna Porcentaje tomará el valor de la columna `Joven` y por tanto tendrá el valor 0.46942, pero si la persona es `Adulto`, entonces tomará el valor de la columna `Adulto` el cual será 0.2791993469851297.\n",
    "\n",
    "PISTA: unir los dos DF mediante join() convencional, y a continuación, crear la nueva columna `Porcentaje` en el resultado, utilizando `when` para ver cuál es el valor que debe tener en cada fila (más concretamente: de qué columna debemos tomarlo) en función del valor de la columna `Age_of_Driver`. No se necesitan variables intermedias; se puede hacer en una secuencia de transformaciones encadenadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee149f7095d0f4bb9048a0672dec71bd",
     "grade": false,
     "grade_id": "join",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "finalDF = accidentesAgeDF.join (viajesPorEdadDF, on= [\"Driver_Journey_Purpose\"])\\\n",
    "    .withColumn (\"Porcentaje\", F.when (F.col (\"Age_of_Driver\")== 7, F.col (\"7\"))\\\n",
    "                .when (F.col (\"Age_of_Driver\")== 8, F.col(\"8\"))\\\n",
    "                .when (F.col (\"Age_of_Driver\")== \"Adolescente\", F.col (\"Adolescente\"))\\\n",
    "                .when (F.col (\"Age_of_Driver\")== \"Joven\", F.col (\"Joven\"))\\\n",
    "                .when (F.col (\"Age_of_Driver\")== \"Adulto\", F.col (\"Adulto\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afede5f5bc886534cae92a88870b9688",
     "grade": true,
     "grade_id": "join_tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sum_cond(df, column, condition): \n",
    "    return(df.where(condition).select(F.sum(column).alias(column)).collect()[0][column])\n",
    "    \n",
    "assert(\"Porcentaje\" in finalDF.columns)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"Adolescente\") - 13344.826819125037) < 0.001)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"Joven\") - 44438.00809518224) < 0.001)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"Adulto\") - 18028.24488479408) < 0.001)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"7\") - 812.0952970292334) < 0.001)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"8\") - 432.2987413617681) < 0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
